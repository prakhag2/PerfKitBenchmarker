diff -ruN inference_results_v1.1/closed/NVIDIA/code/common/system_list.py inference_results_v1.1_new/closed/NVIDIA/code/common/system_list.py
--- inference_results_v1.1/closed/NVIDIA/code/common/system_list.py	2022-05-03 17:49:10.740404915 -0700
+++ inference_results_v1.1_new/closed/NVIDIA/code/common/system_list.py	2022-05-04 12:00:41.425434014 -0700
@@ -325,8 +325,8 @@
     GeForceRTX_3080 = SystemClass("GeForceRTX3080", ["GeForce RTX 3080"], ["2206"], Architecture.Ampere, [1])
     GeForceRTX_3090 = SystemClass("GeForceRTX3090", ["GeForce RTX 3090", "Quadro RTX A6000", "RTX A6000"],
                                   ["2204", "2230"], Architecture.Ampere, [1])
-    A10 = SystemClass("A10", ["A10"], ["2236"], Architecture.Ampere, [1, 8])
-    T4 = SystemClass("T4", ["Tesla T4", "T4 32GB"], ["1EB8", "1EB9"], Architecture.Turing, [1, 8, 20])
+    A10 = SystemClass("A10", ["A10", "A10G"], ["2236"], Architecture.Ampere, [1, 8])
+    T4 = SystemClass("T4", ["Tesla T4", "T4 32GB"], ["1EB8", "1EB9"], Architecture.Turing, [1, 4, 8, 20])
     AGX_Xavier = SystemClass("AGX_Xavier", ["Jetson-AGX"], [], Architecture.Xavier, [1], cpu_arch=CPUArch.aarch64)
     Xavier_NX = SystemClass("Xavier_NX", ["Xavier NX"], [], Architecture.Xavier, [1], cpu_arch=CPUArch.aarch64)
     A30 = SystemClass("A30", ["A30"], ["20B7"], Architecture.Ampere, [1, 8],
diff -ruN inference_results_v1.1/closed/NVIDIA/configs/bert/Server/__init__.py inference_results_v1.1_new/closed/NVIDIA/configs/bert/Server/__init__.py
--- inference_results_v1.1/closed/NVIDIA/configs/bert/Server/__init__.py	2022-05-03 17:49:11.260399435 -0700
+++ inference_results_v1.1_new/closed/NVIDIA/configs/bert/Server/__init__.py	2022-05-04 12:15:59.583562209 -0700
@@ -2371,7 +2371,7 @@
     use_graphs = True
     active_sms = 100
     gpu_batch_size = 8
-    graphs_max_seqlen = 260
+    graphs_max_seqlen = 250
     server_num_issue_query_threads = 20
     server_target_qps = 3300
     soft_drop = 0.992
@@ -2402,6 +2402,100 @@
     scenario = Scenario.Server
     benchmark = Benchmark.BERT
     use_triton = True
+
+
+@ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
+class T4x4(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    bert_opt_seqlen = 384
+    coalesced_tensor = True
+    enable_interleaved = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 2
+    input_dtype = "int32"
+    input_format = "linear"
+    precision = "int8"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy"
+    use_graphs = True
+    active_sms = 100
+    gpu_batch_size = 14
+    graphs_max_seqlen = 260
+    server_num_issue_query_threads = 8
+    server_target_qps = 1100
+    soft_drop = 0.992
+    scenario = Scenario.Server
+    benchmark = Benchmark.BERT
+
+
+@ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99_9, PowerSetting.MaxP)
+class T4x4_HighAccuracy(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    bert_opt_seqlen = 384
+    coalesced_tensor = True
+    enable_interleaved = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int32"
+    input_format = "linear"
+    precision = "fp16"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy"
+    use_graphs = True
+    active_sms = 100
+    gpu_batch_size = 8
+    graphs_max_seqlen = 260
+    server_num_issue_query_threads = 4
+    server_target_qps = 665
+    soft_drop = 0.992
+    scenario = Scenario.Server
+    benchmark = Benchmark.BERT
+
+
+@ConfigRegistry.register(HarnessType.Triton, AccuracyTarget.k_99_9, PowerSetting.MaxP)
+class T4x4_HighAccuracy_Triton(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    bert_opt_seqlen = 384
+    coalesced_tensor = True
+    enable_interleaved = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int32"
+    input_format = "linear"
+    precision = "fp16"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy"
+    use_graphs = True
+    active_sms = 100
+    gpu_batch_size = 8
+    graphs_max_seqlen = 260
+    server_num_issue_query_threads = 4
+    server_target_qps = 665
+    soft_drop = 0.992
+    scenario = Scenario.Server
+    benchmark = Benchmark.BERT
+    use_triton = True
+
+
+@ConfigRegistry.register(HarnessType.Triton, AccuracyTarget.k_99, PowerSetting.MaxP)
+class T4x4_Triton(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    bert_opt_seqlen = 384
+    coalesced_tensor = True
+    enable_interleaved = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 2
+    input_dtype = "int32"
+    input_format = "linear"
+    precision = "int8"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy"
+    use_graphs = True
+    active_sms = 100
+    gpu_batch_size = 14
+    graphs_max_seqlen = 260
+    server_num_issue_query_threads = 8
+    server_target_qps = 1100
+    soft_drop = 0.992
+    scenario = Scenario.Server
+    benchmark = Benchmark.BERT
+    use_triton = True
 
 
 @ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
diff -ruN inference_results_v1.1/closed/NVIDIA/configs/dlrm/Server/__init__.py inference_results_v1.1_new/closed/NVIDIA/configs/dlrm/Server/__init__.py
--- inference_results_v1.1/closed/NVIDIA/configs/dlrm/Server/__init__.py	2022-05-03 17:49:11.260399435 -0700
+++ inference_results_v1.1_new/closed/NVIDIA/configs/dlrm/Server/__init__.py	2022-05-04 12:26:28.568804910 -0700
@@ -2431,6 +2431,116 @@
 
 
 @ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
+class T4x4(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    coalesced_tensor = True
+    enable_interleaved_top_mlp = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int8"
+    input_format = "chw4"
+    output_padding_granularity = 128
+    precision = "int8"
+    sample_partition_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/sample_partition.npy"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/numeric_int8_chw4.npy,${PREPROCESSED_DATA_DIR}/criteo/full_recalib/categorical_int32.npy"
+    use_graphs = False
+    complete_threads = 1
+    deque_timeout_usec = 1
+    embedding_weights_on_gpu_part = 0.5
+    gpu_batch_size = 65500
+    gpu_num_bundles = 1
+    num_staging_batches = 4
+    num_staging_threads = 4
+    server_target_qps = 125000
+    use_jemalloc = True
+    scenario = Scenario.Server
+    benchmark = Benchmark.DLRM
+
+
+@ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99_9, PowerSetting.MaxP)
+class T4x4_HighAccuracy(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    coalesced_tensor = True
+    enable_interleaved_top_mlp = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int8"
+    input_format = "chw4"
+    output_padding_granularity = 128
+    precision = "int8"
+    sample_partition_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/sample_partition.npy"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/numeric_int8_chw4.npy,${PREPROCESSED_DATA_DIR}/criteo/full_recalib/categorical_int32.npy"
+    use_graphs = False
+    complete_threads = 1
+    deque_timeout_usec = 1
+    embedding_weights_on_gpu_part = 0.5
+    gpu_batch_size = 65500
+    gpu_num_bundles = 1
+    num_staging_batches = 4
+    num_staging_threads = 4
+    server_target_qps = 125000
+    use_jemalloc = True
+    scenario = Scenario.Server
+    benchmark = Benchmark.DLRM
+
+
+@ConfigRegistry.register(HarnessType.Triton, AccuracyTarget.k_99_9, PowerSetting.MaxP)
+class T4x4_HighAccuracy_Triton(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    coalesced_tensor = True
+    enable_interleaved_top_mlp = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int8"
+    input_format = "chw4"
+    output_padding_granularity = 128
+    precision = "int8"
+    sample_partition_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/sample_partition.npy"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/numeric_int8_chw4.npy,${PREPROCESSED_DATA_DIR}/criteo/full_recalib/categorical_int32.npy"
+    use_graphs = False
+    complete_threads = 1
+    deque_timeout_usec = 1
+    embedding_weights_on_gpu_part = 0.5
+    gpu_batch_size = 65500
+    gpu_num_bundles = 1
+    num_staging_batches = 4
+    num_staging_threads = 4
+    server_target_qps = 27500
+    use_jemalloc = True
+    scenario = Scenario.Server
+    benchmark = Benchmark.DLRM
+    use_triton = True
+
+
+@ConfigRegistry.register(HarnessType.Triton, AccuracyTarget.k_99, PowerSetting.MaxP)
+class T4x4_Triton(BenchmarkConfiguration):
+    system = System("T4", Architecture.Turing, 4)
+    coalesced_tensor = True
+    enable_interleaved_top_mlp = True
+    gpu_copy_streams = 1
+    gpu_inference_streams = 1
+    input_dtype = "int8"
+    input_format = "chw4"
+    output_padding_granularity = 128
+    precision = "int8"
+    sample_partition_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/sample_partition.npy"
+    tensor_path = "${PREPROCESSED_DATA_DIR}/criteo/full_recalib/numeric_int8_chw4.npy,${PREPROCESSED_DATA_DIR}/criteo/full_recalib/categorical_int32.npy"
+    use_graphs = False
+    complete_threads = 1
+    deque_timeout_usec = 1
+    embedding_weights_on_gpu_part = 0.5
+    gpu_batch_size = 65500
+    gpu_num_bundles = 1
+    num_staging_batches = 4
+    num_staging_threads = 4
+    server_target_qps = 27500
+    use_jemalloc = True
+    scenario = Scenario.Server
+    benchmark = Benchmark.DLRM
+    use_triton = True
+
+
+@ConfigRegistry.register(HarnessType.Custom, AccuracyTarget.k_99, PowerSetting.MaxP)
 class T4x8(BenchmarkConfiguration):
     system = System("T4", Architecture.Turing, 8)
     coalesced_tensor = True
